{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "\n",
    "data = pd.read_csv('chicago_crime.csv')\n",
    "data.dropna(inplace=True)\n",
    "data = data[['Latitude', 'Longitude', 'Date', 'Primary Type', 'Location Description', 'Description', 'Community Area']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "data['Primary Type'] = encoder.fit_transform(data['Primary Type']).astype(float)\n",
    "data['Description'] = encoder.fit_transform(data['Description']).astype(float)\n",
    "data['Location Description'] = encoder.fit_transform(data['Location Description']).astype(float)\n",
    "\n",
    "data['Date'] = pd.to_datetime(data['Date'])\n",
    "data['Month'] = data['Date'].dt.month\n",
    "data['Day'] = data['Date'].dt.day\n",
    "data['Time'] = data['Date'].dt.time\n",
    "\n",
    "def time_to_seconds(t):\n",
    "    return (datetime.timedelta(hours=t.hour, minutes=t.minute, seconds=t.second)).total_seconds()\n",
    "\n",
    "# Apply the function to the 'Time' column\n",
    "data['Time'] = data['Time'].apply(time_to_seconds)\n",
    "\n",
    "data = data.drop('Date', axis=1)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "data[['Latitude', 'Longitude','Community Area','Month', 'Day', 'Time']] = scaler.fit_transform(data[['Latitude', 'Longitude','Community Area','Month', 'Day', 'Time']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "val_data, test_data = train_test_split(test_data, test_size=0.5, random_state=42)\n",
    "\n",
    "X_train = train_data\n",
    "y_train = train_data['Primary Type']\n",
    "X_val = val_data.drop(['Primary Type'], axis=1)\n",
    "y_val = val_data['Primary Type']\n",
    "X_test = test_data.drop(['Primary Type'], axis=1)\n",
    "y_test = test_data['Primary Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Latitude  Longitude  Primary Type  Location Description  Description  \\\n",
      "54604  0.603565   0.755937           2.0                  40.0        203.0   \n",
      "37502  0.656110   0.765570          16.0                  82.0         44.0   \n",
      "28385  0.638180   0.501390          28.0                 101.0          0.0   \n",
      "10175  0.717674   0.510726           2.0                  98.0        203.0   \n",
      "31340  0.819474   0.534605          21.0                 101.0        243.0   \n",
      "...         ...        ...           ...                   ...          ...   \n",
      "37591  0.224241   0.620142           5.0                  16.0        221.0   \n",
      "6318   0.622275   0.519664           2.0                  87.0        203.0   \n",
      "55427  0.569543   0.749149           2.0                  94.0        203.0   \n",
      "865    0.291562   0.876161          25.0                  45.0        208.0   \n",
      "16041  0.395114   0.760484           5.0                 101.0        225.0   \n",
      "\n",
      "       Community Area     Month       Day      Time  \n",
      "54604        0.407895  0.666667  0.033333  0.651842  \n",
      "37502        0.092105  0.333333  0.066667  0.166782  \n",
      "28385        0.328947  0.000000  0.666667  0.785268  \n",
      "10175        0.250000  1.000000  0.400000  0.715775  \n",
      "31340        0.197368  0.000000  0.800000  0.429465  \n",
      "...               ...       ...       ...       ...  \n",
      "37591        0.934211  0.333333  0.100000  0.958999  \n",
      "6318         0.328947  1.000000  0.233333  0.806115  \n",
      "55427        0.421053  0.666667  0.066667  0.458652  \n",
      "865          0.552632  0.666667  1.000000  0.687978  \n",
      "16041        0.513158  0.000000  0.033333  0.583739  \n",
      "\n",
      "[56848 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "#input features present in my dataset\n",
    "num_features = 8\n",
    "#types of crime\n",
    "num_classes = 1 \n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    Dense(256, activation='relu', input_shape=(num_features,)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(64, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.5),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "model.add(Dense(16, activation='relu', input_dim=7))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jarraomar/.pyenv/versions/3.8.13/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: SyntaxWarning: In loss categorical_crossentropy, expected y_pred.shape to be (batch_size, num_classes) with num_classes > 1. Received: y_pred.shape=(None, 1). Consider using 'binary_crossentropy' if you only have 2 classes.\n",
      "  return dispatch_target(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1758/1777 [============================>.] - ETA: 0s - loss: 0.0000e+00 - accuracy: 0.0865"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/jarraomar/.pyenv/versions/3.8.13/lib/python3.8/site-packages/keras/engine/training.py\", line 1852, in test_function  *\n        return step_function(self, iterator)\n    File \"/Users/jarraomar/.pyenv/versions/3.8.13/lib/python3.8/site-packages/keras/engine/training.py\", line 1836, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/jarraomar/.pyenv/versions/3.8.13/lib/python3.8/site-packages/keras/engine/training.py\", line 1824, in run_step  **\n        outputs = model.test_step(data)\n    File \"/Users/jarraomar/.pyenv/versions/3.8.13/lib/python3.8/site-packages/keras/engine/training.py\", line 1788, in test_step\n        y_pred = self(x, training=False)\n    File \"/Users/jarraomar/.pyenv/versions/3.8.13/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/jarraomar/.pyenv/versions/3.8.13/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_14\" is incompatible with the layer: expected shape=(None, 9), found shape=(None, 8)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/jarraomar/Desktop/genius_sheets/databaseHandler.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jarraomar/Desktop/genius_sheets/databaseHandler.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(X_val, y_val), callbacks\u001b[39m=\u001b[39;49m[es])\n",
      "File \u001b[0;32m~/.pyenv/versions/3.8.13/lib/python3.8/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/_5/5yx0jmr50jzfllwklwqq4mh00000gn/T/__autograph_generated_fileo979cu2e.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/jarraomar/.pyenv/versions/3.8.13/lib/python3.8/site-packages/keras/engine/training.py\", line 1852, in test_function  *\n        return step_function(self, iterator)\n    File \"/Users/jarraomar/.pyenv/versions/3.8.13/lib/python3.8/site-packages/keras/engine/training.py\", line 1836, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/jarraomar/.pyenv/versions/3.8.13/lib/python3.8/site-packages/keras/engine/training.py\", line 1824, in run_step  **\n        outputs = model.test_step(data)\n    File \"/Users/jarraomar/.pyenv/versions/3.8.13/lib/python3.8/site-packages/keras/engine/training.py\", line 1788, in test_step\n        y_pred = self(x, training=False)\n    File \"/Users/jarraomar/.pyenv/versions/3.8.13/lib/python3.8/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/jarraomar/.pyenv/versions/3.8.13/lib/python3.8/site-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_14\" is incompatible with the layer: expected shape=(None, 9), found shape=(None, 8)\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[es])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
